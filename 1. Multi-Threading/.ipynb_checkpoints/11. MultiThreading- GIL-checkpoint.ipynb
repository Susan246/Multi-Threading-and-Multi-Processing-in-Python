{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e97c4e7c-1ea9-4fa4-8446-e95c4898f859",
   "metadata": {},
   "source": [
    "# Global Interpreter Lock (GIL):\n",
    "- The GIL is a mutex (short for mutual exclusion) that allows only one thread to execute in the interpreter at a time, even if you have multiple threads running. This lock is necessary because CPython (the most common Python implementation) is not thread-safe in terms of memory management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ca6b3-ea6a-44fd-8ee0-6ef31f37bf90",
   "metadata": {},
   "source": [
    "## What is Reference Counting?\n",
    "- Reference counting is a technique where each object in memory has an associated reference count, which tracks how many references point to that object. Every time a new reference to an object is created, the reference count is incremented. When a reference is deleted or goes out of scope, the reference count is decremented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cdbf68-026d-4eae-8703-7c577bfa808f",
   "metadata": {},
   "source": [
    "### Key Concepts:\n",
    "- Reference Count: The number of references that point to an object.\n",
    "- Object Lifecycle: An object remains in memory as long as its reference count is greater than zero. When the count reaches zero, the object is no longer accessible, and memory can be freed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8bf6a6-7f46-4b7c-b502-f03530a23ff3",
   "metadata": {},
   "source": [
    "### How Reference Counting Works in Python\n",
    "- Every Python object maintains an internal reference count. When you create a variable that refers to an object, the reference count of that object is incremented. When the variable goes out of scope or is explicitly deleted, the reference count is decremented. If the reference count drops to zero, meaning no part of the program references the object anymore, the object is deallocated, and its memory is freed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afafc4c2-b737-4a7e-80ca-4f883e20d9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Creating a simple object (a list in this case)\n",
    "a = [1, 2, 3]\n",
    "\n",
    "# The reference count of the object a refers to is now 1\n",
    "print(sys.getrefcount(a))  # Output will be 2 (1 for a, 1 for sys.getrefcount argument)\n",
    "\n",
    "b = a  # b is now a reference to the same object\n",
    "print(sys.getrefcount(a))  # Output will be 3 (a and b both reference the same object)\n",
    "\n",
    "del a  # Deleting a reference to the object\n",
    "print(sys.getrefcount(b))  # Output will be 2 (only b is referencing the object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7258d765-ed30-44bb-a42a-24134980f4db",
   "metadata": {},
   "source": [
    "### Pros of Reference Counting:\n",
    "- Object Reuse: Reference counting allows objects to be efficiently reused, minimizing memory overhead by preventing the creation of redundant objects.\n",
    "- Predictable and Immediate Deallocation: Objects are immediately deallocated when their reference count reaches zero, ensuring predictable memory management.\n",
    "- Real-Time Collection: Reference counting provides real-time memory collection, as objects are cleaned up immediately when they are no longer in use, ensuring efficient memory usage and avoiding delays in garbage collection cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ce3d28-220e-4c83-a44d-ab39a22d5193",
   "metadata": {},
   "source": [
    "### Cons of Reference Counting:\n",
    "- Not Thread-Safe: Without thread synchronization, reference counting can lead to race conditions in multi-threaded environments.\n",
    "- Circular References: Objects involved in circular references can never have their reference count drop to zero, resulting in memory leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4daf2a7-3a77-41f3-ba05-81db62ac9a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c2dc4a9-0f0f-445d-85fe-328464b52955",
   "metadata": {},
   "source": [
    "### Need of GIL:\n",
    "- The Global Interpreter Lock (GIL) ensures atomicity of reference count updates in Pythonâ€™s memory management. Without the GIL, multiple threads could corrupt the reference count by modifying it simultaneously, leading to memory leaks or premature deallocation of objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8865ef-caed-4889-a3c9-183da7b77c7f",
   "metadata": {},
   "source": [
    "### Working of GIL in case of MultiThreading:\n",
    "#### i. Acquiring the GIL:\n",
    "- When a thread starts execution, it calls the mutex lock function (e.g., pthread_mutex_lock).\n",
    "- If the GIL is available, the thread proceeds; otherwise, it waits in a queue.\n",
    "#### ii. Executing Python Bytecode:\n",
    "- The thread executes Python bytecode once the GIL is acquired.\n",
    "- During this time, other threads are blocked from acquiring the GIL.\n",
    "#### iii. Releasing the GIL\n",
    "- After executing a chunk of bytecode or encountering a blocking operation:\n",
    "- The thread calls the mutex unlock function (e.g., pthread_mutex_unlock).\n",
    "- This allows other threads in the queue to acquire the GIL.\n",
    "#### iv. Thread Switching\n",
    "- The GIL is released periodically (based on bytecode execution count) to ensure other threads can acquire the GIL.\n",
    "- The Python interpreter uses a thread scheduler to determine which thread gets the GIL next.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0353f8a4-5c46-4b2b-930a-0382911c14e8",
   "metadata": {},
   "source": [
    "## MultiTasking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6ea399a-1d5b-46ba-9bd6-d5036f5b2ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Multithreading Demo...\n",
      "Multithreading Execution Time: 1.17716 seconds\n",
      "\n",
      "Running Multiprocessing Demo...\n",
      "Multiprocessing Execution Time: 0.39018 seconds\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Function to perform a heavy computation\n",
    "def heavy_computation():\n",
    "    total = 0\n",
    "    for _ in range(10000000):  \n",
    "        total += 1\n",
    "    return total\n",
    "\n",
    "# Multithreading demonstration\n",
    "def multithreading_demo():\n",
    "    threads = [\n",
    "        threading.Thread(target=heavy_computation),\n",
    "        threading.Thread(target=heavy_computation),\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Start threads\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "\n",
    "    # Wait for threads to complete\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Multithreading Execution Time: {end_time - start_time:.5f} seconds\")\n",
    "\n",
    "# Multiprocessing demonstration\n",
    "def multiprocessing_demo():\n",
    "    processes = [\n",
    "        multiprocessing.Process(target=heavy_computation),\n",
    "        multiprocessing.Process(target=heavy_computation),\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Start processes\n",
    "    for process in processes:\n",
    "        process.start()\n",
    "\n",
    "    # Wait for processes to complete\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Multiprocessing Execution Time: {end_time - start_time:.5f} seconds\")\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running Multithreading Demo...\")\n",
    "    multithreading_demo()\n",
    "\n",
    "    print(\"\\nRunning Multiprocessing Demo...\")\n",
    "    multiprocessing_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1327f31d-aa7d-40dc-9418-a8a0bb67cd8d",
   "metadata": {},
   "source": [
    "### GIL and Threading:\n",
    "- GIL is a lock that ensures only one thread executes Python bytecode at a time.\n",
    "- Although multiple threads can run concurrently in a Python program, only one thread can hold the GIL and execute Python code at any moment.\n",
    "- In a CPU-bound task like heavy_computation, the GIL prevents multiple threads from fully utilizing multiple CPU cores. Threads will take turns to acquire the GIL, which means that even if we have multiple threads, only one is executing Python code at any given time. This leads to suboptimal performance for CPU-bound tasks.\n",
    "\n",
    "### GIL and Multiprocessing:\n",
    "- Multiprocessing avoids the GIL because each process runs in its own memory space and has its own GIL.\n",
    "- This allows each process to run independently on a separate CPU core, enabling true parallelism. For tasks like heavy_computation, this is far more efficient than multithreading because the CPU cores are fully utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee98b593-220a-49c2-9c1c-8e4b04d2b03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9834f480-5b8b-46c2-82ff-2153a09fb1fb",
   "metadata": {},
   "source": [
    "### Why Use Multithreading in Python even there is no true parallelism?\n",
    "- I/O-bound tasks: As mentioned earlier, multithreading is ideal for tasks where the program spends a significant amount of time waiting for external resources (e.g., waiting for data from a disk, network requests, or file reading/writing). In these cases, the GIL has less impact, and threads can work concurrently, making the program more efficient.\n",
    "- Concurrency: Even though there is no true parallelism in CPU-bound tasks, multithreading allows for concurrent execution of multiple tasks. This can be useful in applications that need to handle multiple I/O-bound operations at once (like handling multiple user requests in a server).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fb1220-5ee9-416e-832d-212c298088dc",
   "metadata": {},
   "source": [
    "### Suitable : Web Scraping (I/O-bound Task)\n",
    "- Web scraping is a common I/O-bound task, where multiple threads can download data from multiple URLs concurrently, instead of waiting for each request to finish one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6d3ea-9843-45b5-af64-6c70d1ce4204",
   "metadata": {},
   "source": [
    "### i. Without Multithreading (Sequential Execution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15a70822-4ff2-4fed-b310-da7f6f328fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped: http://example.com - Status Code: 200\n",
      "Scraped: http://example.org - Status Code: 200\n",
      "Scraped: http://example.net - Status Code: 200\n",
      "Time taken without multithreading: 2.7732484340667725 seconds\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\"http://example.com\", \"http://example.org\", \"http://example.net\"]\n",
    "\n",
    "# Function to scrape a single URL\n",
    "def scrape(url):\n",
    "    response = requests.get(url)\n",
    "    print(f\"Scraped: {url} - Status Code: {response.status_code}\")\n",
    "\n",
    "# Without multithreading - Sequentially scrape URLs\n",
    "start_time = time.time()\n",
    "for url in urls:\n",
    "    scrape(url)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken without multithreading: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e24d971-e4cd-4ca5-9a1e-56cd8597e425",
   "metadata": {},
   "source": [
    "### ii. With Multithreading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a5d2d3-8426-419f-8206-7bf3025cefb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped: http://example.net - Status Code: 200Scraped: http://example.com - Status Code: 200\n",
      "\n",
      "Scraped: http://example.org - Status Code: 200\n",
      "Time taken with multithreading: 0.5698778629302979 seconds\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\"http://example.com\", \"http://example.org\", \"http://example.net\"]\n",
    "\n",
    "# Function to scrape a single URL\n",
    "def scrape(url):\n",
    "    response = requests.get(url)\n",
    "    print(f\"Scraped: {url} - Status Code: {response.status_code}\")\n",
    "\n",
    "# With multithreading - Concurrently scrape URLs\n",
    "start_time = time.time()\n",
    "threads = []\n",
    "for url in urls:\n",
    "    thread = threading.Thread(target=scrape, args=(url,))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken with multithreading: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e8fef4-eff6-4b82-898c-10b608cf3ae6",
   "metadata": {},
   "source": [
    "- Without Multithreading: The program will make requests one at a time, waiting for each URL to load before moving to the next one. This results in sequential execution and longer total execution time.\n",
    "\n",
    "- With Multithreading: The program will send requests concurrently, and while one thread is waiting for a response from a URL, other threads can continue to make requests. This results in concurrent execution, reducing the overall execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0badd-3027-4c0c-bd71-3faf6252b207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "630bf9f8-821a-4f14-b85f-8240e109e634",
   "metadata": {},
   "source": [
    "## Then, Why Python still use GIL?\n",
    "- Simplicity: GIL simplifies the interpreter's implementation by ensuring only one thread executes Python bytecode at a time, avoiding complex memory management and thread synchronization.\n",
    "\n",
    "- Thread Safety: It prevents issues with reference counting and memory management in multithreading by making sure only one thread accesses objects at a time.\n",
    "\n",
    "- I/O-bound Task Efficiency: The GIL is released during I/O operations, allowing other threads to run concurrently, making Python multithreading effective for I/O-bound tasks (e.g., web scraping, file I/O).\n",
    "\n",
    "- Backward Compatibility: Removing the GIL would break backward compatibility with existing Python code, requiring significant changes to the interpreter and libraries.\n",
    "\n",
    "- Less Overhead: Managing thread synchronization and memory safely without the GIL would add complexity and performance overhead to Python programs.\n",
    "\n",
    "- Multiprocessing Alternative: For CPU-bound tasks that need true parallelism, Python offers the multiprocessing module, which bypasses the GIL by using separate processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029f07dc-5006-4c98-bad0-a3b792e4c2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "779c69b2-e773-4d78-a769-3e3d8337da48",
   "metadata": {},
   "source": [
    "#### - In Python, due to the GIL, we use multithreading for I/O-bound tasks and multiprocessing for CPU-bound tasks.\n",
    "#### - In general (outside of Python), multithreading is also capable of handling CPU-bound tasks. However, it is typically not used for such tasks because threads are designed to optimize a process's operations for efficiency rather than perform heavy computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a445da-64de-4d99-94b3-966707145e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
